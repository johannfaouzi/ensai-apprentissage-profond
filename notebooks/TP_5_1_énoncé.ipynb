{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avant de débuter ce TP** :\n",
    "\n",
    "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
    "2. **Installez les paquets ci-dessous** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightning torchmetrics torchinfo pyconll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(\"lightning\")\n",
    "logger.propagate = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Missing logger folder.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice de grammaire par transformeur\n",
    "\n",
    "Dans ce notebook, nous allons à nouveau travailler sur le jeu de données [noun verb](https://github.com/google-research-datasets/noun-verb).\n",
    "Ce jeu de données contient des phrases en anglais naturelles où il peut y avoir une certaine ambiguïté sur le rôle d'un mot, c'est-à-dire de savoir s'il s'agit d'un nom ou d'un verbe.\n",
    "\n",
    "Vous trouverez ci-dessous quelques observations de ce jeu de données illustrant la tâche. Le mot en gras est le mot à classer et le mot en italique après la phrase indique la bonne réponse :\n",
    "\n",
    "> Certain insects can damage plumerias, such as mites, **flies**, or aphids. *NOUN*\n",
    "\n",
    "> **Mark** which area you want to distress. *VERB*\n",
    "\n",
    "Par exemple, le mot **flies** peut correspondre à la troisième personne au singulier du verbe *fly* (par exemple *time flies by so fast*), mais également au pluriel du nom *fly* (mouche).\n",
    "De même, le mot **mark** peut correspondre au verbe *mark* (marquer) ou au nom *mark* (marque).\n",
    "\n",
    "Le tâche est donc une classification binaire car il n'y a que deux classes possibles : *nom* ou *verbe*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et prétraitement des données\n",
    "\n",
    "Nous allons appliquer les mêmes étapes de prétraitement des données que dans l'autre notebook, c'est-à-dire transformer chaque token en un vecteur numérique à $50$ dimensions en utilisant les *embeddings* GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data && cd data && wget https://nlp.stanford.edu/data/glove.6B.zip && unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def load_dataset(path='data'):\n",
    "    \"\"\"Load the noun verb dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Chemin du répertoire.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train : Conll\n",
    "        Jeu d'entraînement.\n",
    "\n",
    "    validation : Conll\n",
    "        Jeu de validation.\n",
    "\n",
    "    test : Conll\n",
    "        Jeu d'évaluation.\n",
    "\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pyconll\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    files = ('train.conll', 'dev.conll', 'test.conll')\n",
    "\n",
    "    # Downloads the files if necessary\n",
    "    for file in files:\n",
    "        if not os.path.isfile(os.path.join(path, file)):\n",
    "            url = f'https://raw.githubusercontent.com/google-research-datasets/noun-verb/master/{file}'\n",
    "            urlretrieve(url, os.path.join(path, file))\n",
    "\n",
    "    return (pyconll.load_from_file(os.path.join(path, file)) for file in files)\n",
    "\n",
    "\n",
    "def load_embeddings(path='data'):\n",
    "    \"\"\"Charge les représentations vectorielles GloVe 50d.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Chemin du le répertoire.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    embeddings : dict\n",
    "        Représentations vectorielles GloVe 50d.\n",
    "\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    # Save the results in a dictionary\n",
    "    embeddings = {}\n",
    "\n",
    "    # Get the embedding for each token in the file\n",
    "    mean = torch.zeros(50, dtype=torch.float32)\n",
    "    with open(os.path.join(path, 'glove.6B.50d.txt'), 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            split = line.strip().split(' ')\n",
    "            token = split[0]\n",
    "            value = torch.from_numpy(np.array(split[1:], dtype=np.float32))\n",
    "            embeddings[token] = value\n",
    "            mean += value\n",
    "\n",
    "    # Define the mean embedding for out-of-vocabulary token\n",
    "    embeddings['out_of_vocabulary'] = mean / len(embeddings)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    \"\"\"Prétraite un jeu de données.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : Conll\n",
    "        Jeu de données.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : list[Tensors]\n",
    "        Phrases prétraitées.\n",
    "\n",
    "    y : Tensor\n",
    "        Labels rétraités.\n",
    "    \n",
    "    index : Tensor\n",
    "        Indices des tokens à prédire.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    index = []\n",
    "    mapping = []\n",
    "\n",
    "    label_mapping = {'NON-VERB': 0, 'VERB': 1}\n",
    "\n",
    "    for count, sentence in enumerate(dataset):\n",
    "\n",
    "        embedded_sentence = []\n",
    "        label = None\n",
    "        idx = None\n",
    "\n",
    "        for i, token in enumerate(sentence):\n",
    "\n",
    "            # Get the token in lower cases\n",
    "            token_lower = token.form.lower()\n",
    "\n",
    "            # Get the embedding of the token\n",
    "            if token_lower in embeddings.keys():\n",
    "                embedded_sentence.append(embeddings[token_lower].reshape(1, -1))\n",
    "            else:\n",
    "                embedded_sentence.append(embeddings['out_of_vocabulary'].reshape(1, -1))\n",
    "\n",
    "            # Get the label (if any)\n",
    "            if len(token.feats):\n",
    "                if label is not None:\n",
    "                    raise ValueError(\"Two annotated tokens in a single sentence.\")\n",
    "                label = label_mapping[next(iter(token.feats['POS']))]\n",
    "                idx = i\n",
    "\n",
    "        # Add the preprocessed sample to the dataset only if there is a label available\n",
    "        if label is not None:\n",
    "            X.append(torch.concat(embedded_sentence))\n",
    "            y.append(label)\n",
    "            index.append(idx)\n",
    "            mapping.append(count)\n",
    "\n",
    "    y = torch.tensor(y).to(dtype=torch.float32)\n",
    "    index = torch.tensor(index).to(dtype=torch.int64)\n",
    "\n",
    "    return X, y, index, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "training, validation, test = load_dataset()\n",
    "\n",
    "# Load the embeddings\n",
    "embeddings = load_embeddings()\n",
    "\n",
    "# Preprocess the dataset\n",
    "X_train, y_train, index_train, mapping_train = preprocess_dataset(training)\n",
    "X_val, y_val, index_val, mapping_val = preprocess_dataset(validation)\n",
    "X_test, y_test, index_test, mapping_test = preprocess_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappel\n",
    "\n",
    "Dans un TP précédent, nous avons utilisé un réseau de neurones récurrent bidirectionnel.\n",
    "L'image ci-dessous résume l'architecture que nous avons implémentée :\n",
    "\n",
    "[<img src=\"../figures/brnn_specific_token.png\" width=\"450\"/>](../figures/brnn_specific_token.png)\n",
    "\n",
    "Cette approche a plusieurs limites :\n",
    "\n",
    "* Dans la direction avant, seuls les tokens situés avant le token d'intérêt sont prise en compte. De même, dans la direction arrière, seuls les tokens situés après le token d'intérêt sont pris en compte. En concaténant les deux états cachés, tous les tokens sont pris en compte, mais cela n'intervient que plus tard dans l'architecture.\n",
    "\n",
    "* L'état caché du token d'intérêt doit contenir toute l'information pertinente contenu dans tous les tokens précédents, ce qui peut être difficile pour de longues phrases.\n",
    "\n",
    "\n",
    "## Mécanisme d'attention\n",
    "\n",
    "L'idée principale du mécanisme d'attention est la suivante : au lieu de prendre en compte un seul état caché obtenu par un réseau de neurones récurrent, on peut prendre en compte toutes les entrées en utilisant une **combinaison convexe** des entrées.\n",
    "Ainsi, un vecteur caché n'a plus à contenir toute l'inforformation pertinente car on aura une couche dédiée pour aller chercher les informations pertinentes dans les entrées correspondantes à travers des *poids d'attention*.\n",
    "\n",
    "Une fonction d'attention peut être décrite comme une correspondance entre une *requête* et un ensemble de paires de (*clés*, *valeurs*) pour renvoyer une sortie.\n",
    "La requête, chaque clé, chaque valeur et la sortie sont des vecteurs numériques.\n",
    "Cette sortie est calculée comme une somme pondérée des valeurs, où les poids sont calculés en fonction de la similarité entre la requête et les clés.\n",
    "\n",
    "Il existe plusieurs fonctions mathématiques pour calculer .\n",
    "Ici, la fonction considérée est l'attention basée sur le produit scalaire échelonné (*scaled dot-product attention*) :\n",
    "$$\n",
    "    \\text{Attention}(Q, K, V) = \\text{softmax}\\left( \\frac{Q K^\\top}{\\sqrt{d_k}} \\right) V\n",
    "$$\n",
    "où $Q$, $K$ et $V$ sont les matrices correspondant aux requêtes, aux clés et aux valeurs respectivement, et où $d_k$ est la dimension des vecteurs des requêtes et des clés.\n",
    "L'échelonnage est fait pour empêcher l'échelle des produits scalaires de dépendre trop de la dimension $d_k$.\n",
    "\n",
    "\n",
    "### Attention multi-tête\n",
    "\n",
    "L'idée principale de l'attention multi-tête est de simplement effectuer plusieurs fonctions d'attention au lieu d'une seule, mais sans changer la dimension totale.\n",
    "Pour ce faire, chaque fonction d'attention se fait en plus petites dimensions en projetant linéairement les requêtes, les clés et les valeurs dans différents espaces de plus faible dimension :\n",
    "$$\n",
    "    \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\ldots, \\text{head}_h) W^O \\\\\n",
    "    \\text{où } \\text{head}_i = \\text{Attention}(Q W_i^Q, K W_i^K, V W_i^V) \n",
    "$$\n",
    "\n",
    "The main idea of multi-head attention is simply to perform several attention functions instead of a single one, but without increasing the dimension. It is done by linearly projecting the queries, keys and values $h$ times with different, learned linear projections:\n",
    "$$\n",
    "    \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\ldots, \\text{head}_h) W^O \\\\\n",
    "    \\text{where } \\text{head}_i = \\text{Attention}(Q W_i^Q, K W_i^K, V W_i^V) \n",
    "$$\n",
    "\n",
    "L'image ci-dessous illustre l'attention basée sur le produit scalaire échelonné (à gauche) et l'attention multi-tête (à droite) :\n",
    "\n",
    "[<img src=\"../figures/attention.png\" width=\"650\"/>](../figures/attention.png)\n",
    "\n",
    "## Implémentation dans `PyTorch`\n",
    "\n",
    "L'attention multi-tête est implémentée dans la classe [`torch.nn.MultiheadAttention()`](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html).\n",
    "Les arguments obligatoires de cette classe sont :\n",
    "* `embed_dim` : dimension des vecteurs (les requêtes, les clés et les valeurs),\n",
    "* `num_heads` : nombre de têtes d'attention.\n",
    "Veuillez noter que la dimension totale `embed_dim` est répartie entre les têtes, c'est-à-dire que chaque tête est de dimension `embed_dim / num_heads`.\n",
    "\n",
    "Pour appliquer la passe avant de cette couche, il est nécessaire de fournir en entrée au minimum trois arguments obligatoires : `query` (les requêtes), `key` (les clés) and `value` (les valeurs).\n",
    "Un argument optionnel, `key_padding_mask`, permet d'indiquer quels éléments parmi les clés ignorer dans le calcul de l'attention.\n",
    "Plus d'informations à ce sujet dans la section suivante.\n",
    "\n",
    "\n",
    "### Rembourrage (*padding*)\n",
    "\n",
    "Avec des données séquentielles, on se retrouve souvent à travailler avec des tenseurs de longueur variable.\n",
    "Comme avec les réseaux de neurones récurrents, on utilise le rembourrage (*padding*), c'est-à-dire ajouter éventuellement des zéros à la fin des tenseurs, pour que toutes les observations potentiellement rembourrées du lot aient la même longueur.\n",
    "Cependant, il est nécessaire d'indiquer quells valeurs ont été rembourrées afin que la fonction d'attention ne les utilise pas.\n",
    "C'est exactement ce que l'argument `key_padding_mask` permet de faire.\n",
    "Une représentation possible est un masque binaire où les valeurs `True` indiquent les éléments à ignorer.\n",
    "Le code ci-dessous illustre comment rembourrer une liste de séquences et comment calculer le masque de rembourrage.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "sequence1 = torch.rand(6, 50)  # une séquence de longueur 6\n",
    "sequence2 = torch.rand(10, 50)  # une séquence de longueur 10\n",
    "sequence3 = torch.rand(9, 50)  # une séquence de longueur 9\n",
    "\n",
    "sequences = [sequence1, sequence2, sequence3]\n",
    "\n",
    "# On calcule la longueur de chacune des séquences\n",
    "lens = [sequence.size()[0] for sequence in sequences]\n",
    "max_len = max(lens)\n",
    "\n",
    "# On génère le masque de rembourrage pour la couche d'attention.\n",
    "key_padding_mask = torch.vstack([\n",
    "    torch.cat((torch.full((length,), False), torch.full((max_len - length,), True)))\n",
    "    for length in lens\n",
    "])\n",
    "\n",
    "# On rembourre la liste de séquences\n",
    "sequences_padded = pad_sequence(sequences)\n",
    "```\n",
    "\n",
    "### Question 1\n",
    "\n",
    "On va construire un réseau de neurones récurrent avec l'architecture suivante :\n",
    "\n",
    "* Première couche : attention multi-tête avec une seule tête.\n",
    "* Deuxième couche : couche linéaire avec 50 variables en entrée et 32 variables en sortie + fonction d'action ReLU.\n",
    "* Troisième couche : couche linéaire avec 1 variable en sortie.\n",
    "\n",
    "Pour la couche d'attention, vous utiliserez [`torch.nn.MultiheadAttention()`](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html).\n",
    "Prenez le temps de lire la documentation de cette classe.\n",
    "\n",
    "Quelques remarques importantes :\n",
    "\n",
    "* La méthode `forward()` de [`torch.nn.MultiheadAttention()`](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html) a un argument appelé `need_weights` dont la valeur par défaut est `True`. La documentation propose de remplacer cette valeur par `False` pour utiliser une version plus optimisée et obtenir la meilleure performance. Bien que notre modèle n'utilise pas les poids d'attention, on va laisser la valeur de cet argument à `True` afin de visualiser les poids obtenus. **En particulier, la méthode `forward()` de la classe `AttentionNetwork()` doit renvoyer les poids d'attention**. \n",
    "* La couche d'attention va renvoyer renvoyer les sorties d'attention et les poids d'attention pour tous les tokens. On ne s'intéresse qu'à la sortie et aux poids pour le token d'intérêt (correspondant au mot à labéliser).\n",
    "\n",
    "Complétez le code manquant dans les méthodes `__init__()` et `forward()` de la classe `AttentionNetwork()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class AttentionNetwork(L.LightningModule):\n",
    "    def __init__(self, num_heads=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### BEGIN TODO ###\n",
    "        # Initialisation des couches\n",
    "        #### END TODO ####\n",
    "        \n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        self.accuracy_train = Accuracy(task=\"binary\")\n",
    "        self.accuracy_val = Accuracy(task=\"binary\")\n",
    "        self.accuracy_test = Accuracy(task=\"binary\")\n",
    "\n",
    "    def forward(self, X, index):\n",
    "        \"\"\"Passe avant.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list[Tensor], len = batch_size\n",
    "            Lot de séquences de vecteurs.\n",
    "        \n",
    "        index : tensor, shape = (batch_size,)\n",
    "            Indice du token d'intérêt dans chacune des séquences.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        logits : Tensor, shape = (batch_size,)\n",
    "            Logits.\n",
    "        \n",
    "        attn_weights : list[Tensor], len = batch_size\n",
    "            Liste des poids d'attention pour chaque token d'intérêt.\n",
    "        \"\"\"\n",
    "        ### BEGIN TODO ###\n",
    "        # Calcule la longueur de chacune des séquences\n",
    "\n",
    "        # Génère le masque de rembourrage\n",
    "        \n",
    "        # Rembourre la liste des tenseurs\n",
    "        \n",
    "        # Récupère uniquement les requêtes pour les tokens d'intérêt\n",
    "\n",
    "        # Calcule les sorties et les poids d'attention\n",
    "        \n",
    "        # Enlève le padding dans les poids d'attention\n",
    "        # attn_weights = \n",
    "        \n",
    "        # Applique le perceptron multicouche\n",
    "        # logits = \n",
    "        #### END TODO ####\n",
    "\n",
    "        return logits, attn_weights\n",
    "    \n",
    "    def step(self, batch, dataset):\n",
    "        \"\"\"Effectue une étape.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple\n",
    "            Un lot d'observations. Le premier élément du tuple est le lot\n",
    "            des entrées, le second est le lot des labels.\n",
    "\n",
    "        dataset : {\"training\", \"validation\", \"test\"}\n",
    "            Jeu de données utilisé.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor, shape = (1,)\n",
    "            La fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        # Récupère les données du lot d'observations\n",
    "        X = [item[0].to(self.device) for item in batch]\n",
    "        y = torch.tensor([item[1] for item in batch], device=self.device)\n",
    "        index = torch.tensor([item[2] for item in batch], device=self.device)\n",
    "        \n",
    "        logits, _ = self(X, index)  # Passe avant, qui renvoie les logits\n",
    "        loss = self.loss(logits, y)  # Évaluation de la fonction de coût\n",
    "        y_pred = (logits > 0).to(torch.float32)  # Prédictions du modèle\n",
    " \n",
    "        if dataset == \"training\":\n",
    "            metric = self.accuracy_train\n",
    "            name = \"train\"\n",
    "            bar_step = True\n",
    "        elif dataset == \"validation\":\n",
    "            metric = self.accuracy_val\n",
    "            name = \"val\"\n",
    "            bar_step = False\n",
    "        else:\n",
    "            metric = self.accuracy_test\n",
    "            name = \"test\"\n",
    "            bar_step = False\n",
    "        \n",
    "        acc = metric(y_pred, y)  # Évaluation de la métrique\n",
    "        self.log(f\"loss_{name}\", loss, batch_size=len(y), prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "        self.log(f\"accuracy_{name}\", acc, batch_size=len(y), prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
    "        return self.step(batch, \"training\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"Effectue une étape de validation.\"\"\"\n",
    "        return self.step(batch, \"validation\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
    "        string = f\"Version {self.trainer.logger.version}\"\n",
    "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        string = (f\"\"\"\n",
    "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
    "            -------------------------------------------------\n",
    "            |     Jeu      | Fonction de perte | Exactitude |\n",
    "            | ------------ | ----------------- | ---------- |\n",
    "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['accuracy_train'].item():^12.3%}|\n",
    "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['accuracy_val'].item():^12.3%}|\n",
    "            -------------------------------------------------\n",
    "        \"\"\")\n",
    "        string = '\\n'.join([line.strip() for line in string.strip().split('\\n')])\n",
    "        print(string, \"\\n\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jeux de données (*datasets*) et chargeurs de données (*dataloaders*)\n",
    "\n",
    "Étant donné que le code relatif aux jeux et chargeurs de données reste inchangé par rapport au notebook précédent, il vous est fourni ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    TensorDataset(X_train, y_train, index_train),\n",
    "    batch_size=64, shuffle=True, collate_fn=lambda x: x\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    TensorDataset(X_val, y_val, index_val),\n",
    "    batch_size=64, shuffle=False, collate_fn=lambda x: x\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    TensorDataset(X_test, y_test, index_test),\n",
    "    batch_size=64, shuffle=False, collate_fn=lambda x: x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement\n",
    "\n",
    "On va entraîner notre modèle pendant 10 époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "\n",
    "model_attention = AttentionNetwork()\n",
    "\n",
    "trainer_attention = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    enable_model_summary=False,\n",
    "    logger=CSVLogger('.'),\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=10)]\n",
    ")\n",
    "\n",
    "trainer_attention.fit(\n",
    "    model=model_attention,\n",
    "    train_dataloaders=dataloader_train,\n",
    "    val_dataloaders=dataloader_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "Maintenant que l'on a entraîné notre modèle avec une couche d'attention, on peut visualiser les poids d'attention donnés aux différents tokens d'une phrase pour voir quels mots sont considérés comme importants pour la classification.\n",
    "\n",
    "La fonction `plot_attention_weights()` définie ci-dessous affiche les poids d'attention pour une phrase donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_attention_weights(model, dataset, idx, **kwargs):\n",
    "    \"\"\"Plot a sample from a given dataset and a given index, as well \n",
    "    as the attention weights learned by the model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : LightingModule\n",
    "        Modèle entraîné.\n",
    "    \n",
    "    dataset : {'train', 'validation', 'test'}\n",
    "        Jeu de données.\n",
    "    \n",
    "    idx : int\n",
    "        Indice de l'observation dans le jeu de données.\n",
    "        \n",
    "    kwargs : optional\n",
    "        Autres arguments fournis en entrée de la méthode `forward()`\n",
    "        du modèle entraîné.\n",
    "    \"\"\"\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        dataset = training\n",
    "        X = X_train\n",
    "        y = y_train\n",
    "        index = index_train\n",
    "        mapping = mapping_train\n",
    "    elif dataset == 'validation':\n",
    "        dataset = validation\n",
    "        X = X_val\n",
    "        y = y_val\n",
    "        index = index_val\n",
    "        mapping = mapping_val\n",
    "    elif dataset == 'test':\n",
    "        dataset = test\n",
    "        X = X_test\n",
    "        y = y_test\n",
    "        index = index_test\n",
    "        mapping = mapping_test\n",
    "        \n",
    "    # Check if the index is valid\n",
    "    if not (0 <= idx < len(y)):\n",
    "        raise ValueError(\n",
    "            f\"L'indice fourni n'est pas valable pour ce jeu de données. \"\n",
    "            f\"La taille de ce jeu de données est de {len(y)}.\"\n",
    "        )\n",
    "    \n",
    "    # Get original labels\n",
    "    label_inverse_mapping = {False: 'NOUN', True: 'VERB'}\n",
    "    \n",
    "    # Compute prediction and attention weights\n",
    "    pred, attn = model(X[idx:idx+1], index[idx:idx+1], **kwargs)\n",
    "    y_pred = label_inverse_mapping[pred.item() > 0]\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(14, 2))\n",
    "    plt.imshow(attn[0].detach().numpy().reshape(1, -1), cmap='seismic', vmin=0., vmax=1.)\n",
    "    plt.xticks(-0.5 + np.arange(0, len(X[idx])), [])\n",
    "    plt.yticks([])\n",
    "    plt.tick_params(length=0)\n",
    "\n",
    "    for i, token in enumerate(dataset[mapping[idx]]):\n",
    "        if i == index[idx:idx+1]:\n",
    "            color = 'C0'\n",
    "            fontweight = 'bold'\n",
    "        else:\n",
    "            color = 'k'\n",
    "            fontweight = 'normal'\n",
    "        plt.text(i, -0.6, token.form, color=color, rotation=45, fontweight=fontweight, ha='left')\n",
    "\n",
    "    plt.grid(which='major', color='C2', linestyle='--', linewidth=2)\n",
    "\n",
    "    colorbar = plt.colorbar(orientation='horizontal')\n",
    "    colorbar.set_ticks(np.linspace(0, 1, 6))\n",
    "    colorbar.set_ticklabels([f'{tick: >.1f}' for tick in np.linspace(0, 1, 6)])\n",
    "    \n",
    "    print(f\"True label: {label_inverse_mapping[y[idx].item() == 1]}\")\n",
    "    print(f\"Predicted label: {label_inverse_mapping[pred.item() > 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2\n",
    "\n",
    "Utilisez la fonction `plot_attention_weights()` pour afficher les poids d'attention de chaque token pour quelques phrases des jeux d'entraînement, de validation et d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez peut-être remarqué que la performance d'une modèle n'est pas exceptionnelle, avec un score de précision (*accuracy*), c'est-à-dire la proportion de bonnes réponses, d'environ $70\\%$.\n",
    "Pour rappel, avec un modèle trivial en ne prédisant que des verbes, on obtiendrait les performances suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Propotion de verbes dans le jeu d'entraînement : {y_train.mean().item():.2%}\")\n",
    "print(f\"Propotion de verbes dans le jeu de validation : {y_val.mean().item():.2%}\")\n",
    "print(f\"Propotion de verbes dans le jeu d'évaluation : {y_test.mean().item():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module d'attention est un élément essentiel de l'architecture d'un transformeur, mais cette architecture est bien plus complexe et n'utilise pas qu'un seul module d'attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformeur\n",
    "\n",
    "L'image ci-dessous illustre l'architecture d'un transformeur : \n",
    "\n",
    "[<img src=\"../figures/transformer.png\" width=\"450\"/>](../figures/transformer.png)\n",
    "\n",
    "Cette architecture est composée de deux parties :\n",
    "\n",
    "* L'encodeur (à gauche) est constitué d'une pile de $N$ ($N = 6$ dans l'architecture originale) couches d'encodage ayant toutes la même architecture. Chaque couche d'encodage est composée de deux sous-couches. La première sous-couche correspond l'attention multi-tête, tandis que la seconde sous-couche est un simple perceptron multicouche (2 couches linéaires avec la fonction d'activation ReLU entre les deux).\n",
    "\n",
    "* Le décodeur (à droite) est constitué d'une pile de $N$ ($N = 6$ dans l'architecture originale) couches de décodage ayant toutes la même architecture. Chaque couche de décodage est composée de deux sous-couches. \n",
    "\n",
    "\n",
    "### Implémentation dans `PyTorch`\n",
    "\n",
    "`PyTorch` met à disposition plusieurs classes pour les [différentes couches d'un transformeur](https://pytorch.org/docs/stable/nn.html#transformer-layers) :\n",
    "\n",
    "* [`torch.nn.Transformer()`](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html) : un transformeur complet.\n",
    "* [`torch.nn.TransformerEncoder()`](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html) : un encodeur de transformeur (c'est-à-dire une pile de plusieurs couches d'encodage de transformeur).\n",
    "* [`torch.nn.TransformerDecoder()`](https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html) : un décodeur de transformeur (c'est-à-dire une pile de plusieurs couches de décodage de transformeur).\n",
    "* [`torch.nn.TransformerEncoderLayer()`](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html) : une couche d'encodage d'un transformeur.\n",
    "* [`torch.nn.TransformerDecoderLayer()`](https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html) : une couche de décodage d'un transformeur.\n",
    "\n",
    "\n",
    "### Question 3\n",
    "\n",
    "On va construire un modèle dont l'architecture est basée sur celle du transformeur.\n",
    "L'encodeur sert à apprendre un code de l'entrée.\n",
    "Le décodeur d'un transformeur sert à générer la séquence en sortie à partir du code de l'entrée (par exemple la traduction d'une phrase).\n",
    "Ici, nous n'avons pas besoin de générer une séquence en sortie, nous n'avons donc pas besoin du décodeur.\n",
    "\n",
    "L'encodeur du transformeur renvoie un code de la séquence en entrée, c'est-à-dire un code pour chacun des tokens de la phrase.\n",
    "Nous ne sommes intéressés que par le code du token d'intérêt (le mot à labéliser), nous ne garderons donc que ce code dans la sortie.\n",
    "\n",
    "L'architecture de notre modèle sera la suivante :\n",
    "* *Première couche* : encodeur de transformeur ;\n",
    "* *Deuxième couche* : couche linéaire avec $50$ variables en entrée et $1$ variable en sortie.\n",
    "\n",
    "Complétez le code manquant dans la méthode `__init__()` de la classe `TransformerNetwork()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNetwork(L.LightningModule):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_layers : int (default = 6)\n",
    "        Nombre de couches d'encodage.\n",
    "        \n",
    "    nhead : int (default = 5)\n",
    "        Nombre de têtes dans l'attention multi-tête.\n",
    "    \n",
    "    dropout_encoder_layer : float (default = 0.0)\n",
    "        Taux de dropout de chaque couche d'encodage.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers=6, nhead=5, dropout_encoder_layer=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### BEGIN TODO ###\n",
    "        # self.transformer_encoder = \n",
    "        # self.linear = \n",
    "        #### END TODO ####\n",
    "\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.accuracy_train = Accuracy(task=\"binary\")\n",
    "        self.accuracy_val = Accuracy(task=\"binary\")\n",
    "        self.accuracy_test = Accuracy(task=\"binary\")\n",
    "\n",
    "    def forward(self, X, index, compute_attn_weights=False):\n",
    "        \"\"\"Forward method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list[Tensor], len = batch_size\n",
    "            Sequence of embeddings.\n",
    "\n",
    "        index : tensor, shape = (batch_size,)\n",
    "            Index of the token of interest in each sequence.\n",
    "        \n",
    "        compute_attn_weights : False\n",
    "            Si True, les poids d'attention de la première couche\n",
    "            de l'encodeur sont calculés et renvoyés.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        logits : Tensor, shape = (batch_size,)\n",
    "            Logits.\n",
    "        \n",
    "        attn_weights : Tensor\n",
    "\n",
    "        \"\"\"\n",
    "        # Calcule la longueur de chacune des séquences\n",
    "        lens = [sequence.size()[0] for sequence in X]\n",
    "        max_len = max(lens)\n",
    "        \n",
    "        # Génère le masque de rembourrage\n",
    "        key_padding_mask = torch.vstack([\n",
    "            torch.concat((torch.full((length,), False), torch.full((max_len - length,), True)))\n",
    "            for length in lens\n",
    "        ]).to(self.device)\n",
    "\n",
    "        # Rembourre les séquences les plus petites\n",
    "        X_padded = pad_sequence(X)\n",
    "\n",
    "        # Encodeur du transformeur\n",
    "        transformer_encoder_output = self.transformer_encoder(\n",
    "            X_padded, src_key_padding_mask=key_padding_mask\n",
    "        )\n",
    "\n",
    "        # Récupère la sortie de l'attention pour les tokens d'intérêt seulement\n",
    "        h = torch.vstack([transformer_encoder_output[idx, i] for i, idx in enumerate(index)])\n",
    "        \n",
    "        # Applique la couche linéaire\n",
    "        logits = torch.squeeze(self.linear(h))\n",
    "        \n",
    "        if not compute_attn_weights:\n",
    "            return logits\n",
    "        \n",
    "        else:\n",
    "            # Calcule les poids d'attention de la première couche\n",
    "            _, attn_output_weights = self.transformer_encoder.layers[0].self_attn(\n",
    "                X_padded, X_padded, X_padded\n",
    "            )\n",
    "\n",
    "            # Récupère les poids de l'attention pour les tokens d'intérêt seulement\n",
    "            attn_weights = [\n",
    "                attn_output_weights[i, idx, :length] for i, (idx, length) in enumerate(zip(index, lens))\n",
    "            ]\n",
    "\n",
    "            return logits, attn_weights\n",
    "    \n",
    "    def step(self, batch, dataset):\n",
    "        \"\"\"Effectue une étape.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple\n",
    "            Un lot d'observations. Le premier élément du tuple est le lot\n",
    "            des entrées, le second est le lot des labels.\n",
    "\n",
    "        dataset : {\"training\", \"validation\", \"test\"}\n",
    "            Jeu de données utilisé.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor, shape = (1,)\n",
    "            La fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        # Récupère les données du lot d'observations\n",
    "        X = [item[0].to(self.device) for item in batch]\n",
    "        y = torch.tensor([item[1] for item in batch], device=self.device)\n",
    "        index = torch.tensor([item[2] for item in batch], device=self.device)\n",
    "        \n",
    "        logits = self(X, index, compute_attn_weights=False)  # Passe avant, qui renvoie les logits\n",
    "        loss = self.loss(logits, y)  # Évaluation de la fonction de coût\n",
    "        y_pred = (logits > 0).to(torch.float32)  # Prédictions du modèle\n",
    " \n",
    "        if dataset == \"training\":\n",
    "            metric = self.accuracy_train\n",
    "            name = \"train\"\n",
    "            bar_step = True\n",
    "        elif dataset == \"validation\":\n",
    "            metric = self.accuracy_val\n",
    "            name = \"val\"\n",
    "            bar_step = False\n",
    "        else:\n",
    "            metric = self.accuracy_test\n",
    "            name = \"test\"\n",
    "            bar_step = False\n",
    "        \n",
    "        acc = metric(y_pred, y)  # Évaluation de la métrique\n",
    "        self.log(f\"loss_{name}\", loss, batch_size=len(y), prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "        self.log(f\"accuracy_{name}\", acc, batch_size=len(y), prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
    "        return self.step(batch, \"training\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"Effectue une étape de validation.\"\"\"\n",
    "        return self.step(batch, \"validation\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
    "        string = f\"Version {self.trainer.logger.version}\"\n",
    "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        string = (f\"\"\"\n",
    "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
    "            -------------------------------------------------\n",
    "            |     Jeu      | Fonction de perte | Exactitude |\n",
    "            | ------------ | ----------------- | ---------- |\n",
    "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['accuracy_train'].item():^12.3%}|\n",
    "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['accuracy_val'].item():^12.3%}|\n",
    "            -------------------------------------------------\n",
    "        \"\"\")\n",
    "        string = '\\n'.join([line.strip() for line in string.split('\\n')])\n",
    "        print(string)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Entraîner un nouveau modèle avec l'architecture définie ci-dessus, avec de $2$ couches d'encodage et $1$ tête, pendant $10$ époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN TODO ###\n",
    "# model_transformer = \n",
    "#### END TODO ####\n",
    "\n",
    "trainer_transformer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    enable_model_summary=False,\n",
    "    logger=CSVLogger('.'),\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=10)]\n",
    ")\n",
    "\n",
    "trainer_transformer.fit(\n",
    "    model=model_transformer,\n",
    "    train_dataloaders=dataloader_train,\n",
    "    val_dataloaders=dataloader_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Visualisez les poids de la première couche d'attention générés par ce nouveau modèle grâce à la fonction `plot_attention_weights()` pour quelques phrases des jeux d'entraînement, de validation et d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_weights(model_transformer, 'train', 0, compute_attn_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
